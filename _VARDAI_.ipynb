{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nKruSuw1ynTQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "V_vardai = []\n",
        "M_vardai = []\n",
        "\n",
        "for key in ['a', 'b', 'c', 'c-2', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l',\n",
        "            'm', 'n', 'o', 'p', 'r', 's', 's-2', 't', 'u', 'v', 'z', 'z-2']:\n",
        "    V_url = f'https://vardai.vlkk.lt/sarasas/{key}/?lytis=vyro&kilme='\n",
        "    M_url = f'https://vardai.vlkk.lt/sarasas/{key}/?lytis=moters&kilme='\n",
        "\n",
        "    response = requests.get(V_url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    V_links = soup.find_all('a', class_='names_list__links names_list__links--man')\n",
        "    V_vardai += [name.text for name in V_links]\n",
        "\n",
        "    response = requests.get(M_url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    M_links = soup.find_all('a', class_='names_list__links names_list__links--woman')\n",
        "    M_vardai += [name.text for name in M_links]\n",
        "\n",
        "V_vardai = [name for name in V_vardai if name.endswith('s')]\n",
        "M_vardai = [name for name in M_vardai if not (name.endswith('l') or name.endswith('n') or name.endswith('e'))]\n",
        "\n",
        "np.savetxt('Vyru_vardai.txt', V_vardai, fmt='%s', header='name', comments='', newline='\\n')\n",
        "np.savetxt('Moteru_vardai.txt', M_vardai, fmt='%s', header='name', comments='', newline='\\n')\n",
        "np.savetxt('Visi_vardai.txt', V_vardai + M_vardai, fmt='%s', header='name', comments='', newline='\\n')"
      ],
      "metadata": {
        "id": "_nBz4_ydyrNW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(V_vardai), len(M_vardai)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMhGARe2yh0w",
        "outputId": "2343e99d-dba6-437c-82db-3c8ce2aa0fff"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3409, 4086)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('Visi_vardai.txt', 'r') as file:\n",
        "    lines = file.readlines()\n",
        "    print(\"\".join(lines[:10]))\n",
        "    print(\"\".join(lines[5000:5010]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5N6ys4fMwrm",
        "outputId": "8358d79c-db22-4ee4-d097-99fe667e3da5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name\n",
            "Ãbas\n",
            "Ãbdijus\n",
            "Abdònas\n",
            "Ãbelis\n",
            "Ãbis\n",
            "Abraõmas\n",
            "Abrõmas\n",
            "Achìlas\n",
            "Achmèdas\n",
            "\n",
            "Gìlma\n",
            "Gìlmantė\n",
            "Gìlmė\n",
            "Gìlmina\n",
            "Gìlminta\n",
            "Gìlmintė\n",
            "Gilvidà\n",
            "Gilvìlė\n",
            "Gìlvina\n",
            "Gilvydà\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NameDataset(Dataset):\n",
        "    def __init__(self, male_file, female_file):\n",
        "        male_data = pd.read_csv(male_file, header=None, names=['name'])\n",
        "        female_data = pd.read_csv(female_file, header=None, names=['name'])\n",
        "\n",
        "        male_data['gender'] = 0  # Vyras = 0\n",
        "        female_data['gender'] = 1  # Moteris = 1\n",
        "\n",
        "        self.data = pd.concat([male_data, female_data])\n",
        "        self.names = self.data['name'].str.strip().str.lower().tolist()\n",
        "        self.genders = self.data['gender'].tolist()\n",
        "\n",
        "        all_names = ''.join(self.names)\n",
        "\n",
        "\n",
        "\n",
        "        unwanted_chars = set('xwq')\n",
        "        # Remove unwanted characters from the full dataset\n",
        "        filtered_chars = [char for char in all_names if char not in unwanted_chars]\n",
        "\n",
        "\n",
        "\n",
        "        self.chars = sorted(set(all_names + ' '))\n",
        "        self.char_to_int = {c: i for i, c in enumerate(self.chars)}\n",
        "        self.int_to_char = {i: c for c, i in self.char_to_int.items()}\n",
        "        self.vocab_size = len(self.chars)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.names)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        name = self.names[idx]\n",
        "        gender = self.genders[idx]\n",
        "        name += ' '  # Add end-of-sequence marker\n",
        "        encoded_name = [self.char_to_int[char] for char in name]\n",
        "        return torch.tensor(encoded_name, dtype=torch.long), torch.tensor(gender, dtype=torch.long)\n"
      ],
      "metadata": {
        "id": "EcUKC6nfyuVS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_collate(batch):\n",
        "    names, genders = zip(*batch)\n",
        "    padded_seqs = pad_sequence(names, batch_first=True, padding_value=0)\n",
        "    input_seq = padded_seqs[:, :-1]\n",
        "    target_seq = padded_seqs[:, 1:]\n",
        "    genders = torch.stack(genders)  # Stack gender tensors\n",
        "    return input_seq, target_seq, genders"
      ],
      "metadata": {
        "id": "b6e5M1Y6y-Cr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = NameDataset('Vyru_vardai.txt', 'Moteru_vardai.txt')\n",
        "loader = DataLoader(dataset, batch_size=32, collate_fn=pad_collate, shuffle=True)\n",
        "\n",
        "for input_seq, target_seq, genders in loader:\n",
        "    print(f\"Input shape: {input_seq.shape}, Target shape: {target_seq.shape}, Gender shape: {genders.shape}\")\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juShCcC7y9_4",
        "outputId": "c8cfd117-9bdc-4286-be43-dae5f9b892c6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([32, 12]), Target shape: torch.Size([32, 12]), Gender shape: torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GenderAwareTransformer(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size, num_heads, forward_expansion):\n",
        "        super(GenderAwareTransformer, self).__init__()\n",
        "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
        "        self.gender_embed = nn.Embedding(2, embed_size)  # 2 for male/female\n",
        "        self.positional_encoding = nn.Parameter(torch.randn(1, 100, embed_size))\n",
        "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=embed_size, nhead=num_heads)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=1)\n",
        "        self.output_layer = nn.Linear(embed_size, vocab_size)\n",
        "\n",
        "    def forward(self, x, gender):\n",
        "        # Get embeddings\n",
        "        char_embeddings = self.embed(x)\n",
        "        gender_embeddings = self.gender_embed(gender).unsqueeze(1).expand(-1, x.size(1), -1)\n",
        "\n",
        "        # Combine character and gender embeddings\n",
        "        x = char_embeddings + gender_embeddings + self.positional_encoding[:, :x.size(1), :]\n",
        "        x = self.transformer_encoder(x)\n",
        "        x = self.output_layer(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "YBI1uidUy99P"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Loop\n",
        "def train_model(model, dataloader, epochs=10):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        batch_count = 0\n",
        "\n",
        "        for batch_idx, (input_seq, target_seq, genders) in enumerate(dataloader):\n",
        "            optimizer.zero_grad()\n",
        "            output = model(input_seq, genders)\n",
        "            loss = criterion(output.transpose(1, 2), target_seq)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            batch_count += 1\n",
        "\n",
        "        average_loss = total_loss / batch_count\n",
        "        print(f'Epoch {epoch+1}, Average Loss: {average_loss}')"
      ],
      "metadata": {
        "id": "KDx9Ez7Jy96p"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample(model, dataset, gender, start_str='a', max_length=20, temperature=1.0):\n",
        "    assert temperature > 0, \"Temperature must be greater than 0\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        start_str = start_str.lower()\n",
        "        chars = [dataset.char_to_int[c] for c in start_str]\n",
        "        input_seq = torch.tensor(chars).unsqueeze(0)\n",
        "        gender_tensor = torch.tensor([gender])  # 0 for male, 1 for female\n",
        "\n",
        "        output_name = start_str\n",
        "        last_char = start_str[-1]  # Track the last character to avoid repeating it\n",
        "\n",
        "        for _ in range(max_length - len(start_str)):\n",
        "            output = model(input_seq, gender_tensor)\n",
        "            probabilities = torch.softmax(output[0, -1], dim=0)\n",
        "\n",
        "            # Apply temperature scaling\n",
        "            logits = output[0, -1] / temperature\n",
        "            probabilities = torch.softmax(logits, dim=0)\n",
        "\n",
        "            next_char_idx = torch.multinomial(probabilities, 1).item()\n",
        "            next_char = dataset.int_to_char[next_char_idx]\n",
        "\n",
        "            while next_char == last_char:\n",
        "                next_char_idx = torch.multinomial(probabilities, 1).item()\n",
        "                next_char = dataset.int_to_char[next_char_idx]\n",
        "\n",
        "            if next_char == ' ':\n",
        "                break\n",
        "\n",
        "            output_name += next_char\n",
        "            input_seq = torch.cat([input_seq, torch.tensor([[next_char_idx]])], dim=1)\n",
        "\n",
        "        return output_name.capitalize()"
      ],
      "metadata": {
        "id": "KILnuiTIy94T"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = NameDataset('Vyru_vardai.txt', 'Moteru_vardai.txt')\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=pad_collate)\n",
        "\n",
        "model = GenderAwareTransformer(\n",
        "    vocab_size=dataset.vocab_size,\n",
        "    embed_size=128,\n",
        "    num_heads=8,\n",
        "    forward_expansion=4\n",
        ")\n",
        "train_model(model, dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzn0FiP6y91f",
        "outputId": "17ba7f26-8322-401a-f254-0dba475a9a32"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Average Loss: 1.4598489157696988\n",
            "Epoch 2, Average Loss: 1.295778157863211\n",
            "Epoch 3, Average Loss: 1.2731711760480353\n",
            "Epoch 4, Average Loss: 1.2648672710073756\n",
            "Epoch 5, Average Loss: 1.2537640515794146\n",
            "Epoch 6, Average Loss: 1.2511995980080137\n",
            "Epoch 7, Average Loss: 1.2465078825646259\n",
            "Epoch 8, Average Loss: 1.2448389329808824\n",
            "Epoch 9, Average Loss: 1.2424808215587697\n",
            "Epoch 10, Average Loss: 1.23708210549456\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "print(\"Vyrų vardai:\")\n",
        "for _ in range(10):\n",
        "    random_start_letter = random.choice(dataset.chars)\n",
        "    name = sample(model, dataset, gender=0, start_str='R', temperature=0.5)\n",
        "    print(name)\n",
        "\n",
        "print(\"\\nMoterų vardai:\")\n",
        "for _ in range(10):\n",
        "    random_start_letter = random.choice(dataset.chars)\n",
        "    name = sample(model, dataset, gender=1, start_str=random_start_letter, temperature=0.5)\n",
        "    print(name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1zi7U6py9xC",
        "outputId": "793240ee-dad1-4685-eb7e-06dea91e64eb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vyrų vardai:\n",
            "Rìnijus\n",
            "Rãgas\n",
            "Rìmas\n",
            "Rãmas\n",
            "Rìstas\n",
            "Rãnas\n",
            "Rámas\n",
            "Raũtas\n",
            "Rãtas\n",
            "Rìlijus\n",
            "\n",
            "Moterų vardai:\n",
            "Ęertrà\n",
            "Gamà\n",
            "Daijà\n",
            "Ylinà\n",
            "Jùlintà\n",
            "Ỹìdrina\n",
            "Daistė\n",
            "Ỹilintà\n",
            "Jórintė\n",
            "Naulijà\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), '/content/name_model.pt')\n",
        "\n",
        "mappings = {\n",
        "    'char_to_int': dataset.char_to_int,\n",
        "    'int_to_char': {str(k): v for k, v in dataset.int_to_char.items()},\n",
        "    'vocab_size': dataset.vocab_size\n",
        "}\n",
        "import json\n",
        "with open('/content/name_mappings.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(mappings, f, ensure_ascii=False, indent=2)"
      ],
      "metadata": {
        "id": "_0a4yKYuVlOt"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/content/name_model.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "UnkwtJNJ6OaA",
        "outputId": "3a91dd84-8ff9-4a54-deef-8036023ead8f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f7012e04-6306-4dff-ada2-cfe78cef9552\", \"name_model.pt\", 4859234)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/content/name_mappings.json')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "-ZZN5KM16V6P",
        "outputId": "23af3d0d-9bcb-40d5-cb11-d5a1141135e1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_efff9383-6c11-4ec2-8753-a05e55183cd7\", \"name_mappings.json\", 1532)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}